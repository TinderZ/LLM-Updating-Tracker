import json
import os
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡ (ç”¨äºæœ¬åœ°å¼€å‘)
load_dotenv()

# --- é…ç½®åŒº ---
DATA_FILE = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'docs', 'data.json')

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
# å¦‚æœä½¿ç”¨ OpenAIï¼ŒAPI_KEY å­˜åœ¨ GitHub Secrets çš„ OPENAI_API_KEY
# å¦‚æœä½¿ç”¨ Perplexity (æ¨èç”¨äºæœç´¢)ï¼ŒBASE_URL ä¸º https://api.perplexity.ai
API_KEY = os.getenv("OPENAI_API_KEY")
BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
MODEL_NAME = os.getenv("LLM_MODEL", "gpt-4o") # å¦‚æœæ˜¯ Perplexityï¼Œæ”¹ä¸º sonar ç­‰æ¨¡å‹

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

def load_existing_data():
    """åŠ è½½ç°æœ‰æ•°æ®"""
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

def save_data(data):
    """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
    # æŒ‰æ—¥æœŸæ’åºï¼Œæœ€æ–°çš„åœ¨å‰é¢
    data.sort(key=lambda x: datetime.strptime(x['update_date'], '%Y-%m-%d'), reverse=True)
    with open(DATA_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

def get_updates_from_llm(existing_models):
    """è°ƒç”¨æ”¯æŒæœç´¢çš„ LLM è·å–æ›´æ–°ä¿¡æ¯"""
    today = datetime.now().strftime('%Y-%m-%d')
    
    # æ„é€  Prompt
    # existing_models ç”¨äºå‘Šè¯‰ LLM å“ªäº›æˆ‘ä»¬å·²ç»çŸ¥é“äº†ï¼Œé¿å…é‡å¤
    prompt = f"""
    ä»Šå¤©æ˜¯ {today}ã€‚ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI è¡Œä¸šåˆ†æå¸ˆï¼Œè´Ÿè´£è¿½è¸ªå…¨çƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°å‘å¸ƒå’Œé‡å¤§æ›´æ–°ã€‚
    
    è¯·æœç´¢å¹¶åˆ—å‡ºåœ¨ {today}ï¼ˆæˆ–æœ€è¿‘ 24 å°æ—¶å†…ï¼‰æ–°å‘å¸ƒçš„æ¨¡å‹æˆ–é‡å¤§ç‰ˆæœ¬æ›´æ–°ã€‚
    
    é‡ç‚¹å…³æ³¨ï¼šOpenAI, Anthropic, Google, Meta, xAI, DeepSeek, æ™ºè°±AI, é˜¿é‡Œå·´å·´(Qwen), å­—èŠ‚è·³åŠ¨, è…¾è®¯, MiniMax, æœˆä¹‹æš—é¢(Kimi) ç­‰ã€‚
    
    ç›®å‰æˆ‘ä»¬å·²æœ‰çš„æ¨¡å‹åˆ—è¡¨ï¼ˆéƒ¨åˆ†ï¼‰: {', '.join(existing_models[:5])}...
    
    è¯·è¿”å›ä¸€ä¸ª JSON æ•°ç»„ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
    [
        {{
            "company": "å…¬å¸åç§°",
            "model_name": "æ¨¡å‹å‡†ç¡®åç§°",
            "update_date": "YYYY-MM-DD",
            "blog_url": "å®˜æ–¹å…¬å‘Šæˆ–æŠ€æœ¯åšå®¢é“¾æ¥",
            "license_type": "open_source æˆ– closed_source",
            "features_zh": "ä¸­æ–‡ç‰¹æ€§ç®€è¿°ï¼ˆ50å­—ä»¥å†…ï¼‰",
            "features_en": "English features summary (short)"
        }}
    ]
    
    æ³¨æ„ï¼š
    1. å¿…é¡»æ˜¯çœŸå®çš„å‘å¸ƒï¼Œä¸¥ç¦ç¼–é€ ã€‚
    2. å¦‚æœä»Šå¤©æ²¡æœ‰æ–°æ¨¡å‹å‘å¸ƒï¼Œè¯·è¿”å›ç©ºæ•°ç»„ []ã€‚
    3. åªè¦è¿”å› JSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ã€‚
    """

    print(f"æ­£åœ¨è°ƒç”¨ LLM æœç´¢ä»Šæ—¥æ›´æ–° (Model: {MODEL_NAME})...")
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåªè¾“å‡º JSON çš„ AI åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            # å¼€å¯ JSON æ¨¡å¼ (å¦‚æœä¾›åº”å•†æ”¯æŒ)
            response_format={"type": "json_object"} if "gpt" in MODEL_NAME else None
        )
        
        content = response.choices[0].message.content
        # å°è¯•è§£æç»“æœ
        # æœ‰äº›é OpenAI æ¨¡å‹å¯èƒ½ä¼šåœ¨å†…å®¹å‰ååŠ  ```json ... ```
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
            
        result = json.loads(content)
        # å¦‚æœè¿”å›çš„æ˜¯ {"updates": [...]} è¿™ç§æ ¼å¼ï¼Œæå–æ•°ç»„
        if isinstance(result, dict) and "updates" in result:
            return result["updates"]
        return result if isinstance(result, list) else []

    except Exception as e:
        print(f"âŒ è°ƒç”¨ LLM å¤±è´¥: {e}")
        return []

def is_duplicate(new_item, existing_data):
    """ç®€å•å»é‡é€»è¾‘"""
    for item in existing_data:
        if (item['company'].lower() == new_item['company'].lower() and 
            item['model_name'].lower() == new_item['model_name'].lower()):
            return True
    return False

def main():
    existing_data = load_existing_data()
    existing_model_names = [item['model_name'] for item in existing_data]
    
    new_updates = get_updates_from_llm(existing_model_names)
    
    if not new_updates:
        print("â„¹ï¸ ä»Šæ—¥æœªå‘ç°æ–°æ¨¡å‹å‘å¸ƒã€‚")
        return

    added_count = 0
    for update in new_updates:
        if not is_duplicate(update, existing_data):
            existing_data.append(update)
            added_count += 1
            print(f"âœ… å‘ç°æ–°æ¨¡å‹: {update['company']} - {update['model_name']}")
    
    if added_count > 0:
        save_data(existing_data)
        print(f"ğŸ‰ æˆåŠŸæ·»åŠ  {added_count} æ¡æ–°æ›´æ–°ï¼æ•°æ®å·²ä¿å­˜åˆ° docs/data.json")
    else:
        print("â„¹ï¸ å‘ç°çš„æ›´æ–°å‡å·²åœ¨æ•°æ®åº“ä¸­ã€‚")

if __name__ == "__main__":
    main()
